{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4662e0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "import os\n",
    "import joblib\n",
    "import scipy\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pingouin as pg\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as sm\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "import fa\n",
    "import subspace\n",
    "import data_loader as io\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc95b60f",
   "metadata": {
    "title": "imports"
   },
   "outputs": [],
   "source": [
    "## Global variables and useful functions\n",
    "\n",
    "SUBJS = 'ABCDFIJWXYZ'\n",
    "SAVEFIG = False\n",
    "VERBOSE = False\n",
    "TASK_NAMES = ['podcast','pursuit','rotations']\n",
    "TASK_KEY = dict(zip(TASK_NAMES, ['C','S','R']))\n",
    "TASK_CLR = dict(zip(TASK_NAMES, ['#F24B69','#24A5F5','#FFBA36']))\n",
    "TASK_SHAPE = dict(zip(TASK_NAMES, ['s','o','^']))\n",
    "TASK_PAIRS = ['CS','CR','RS']\n",
    "TASK_PAIRS_CLR = dict(zip(TASK_PAIRS, [\"#66c5cc\",\"#f6cf71\",\"#f89c74\"]))\n",
    "SUBJ_CLR = dict(zip(SUBJS, [plt.cm.rainbow(i/len(SUBJS)) for i in range(len(SUBJS))]))\n",
    "AREA_CLR = {'HPC': 'purple', 'ACC': 'green'}\n",
    "\n",
    "def read_all_sessions(max_gap_dur_secs: float = 1.0,\n",
    "                      bin_size: int = 200,\n",
    "                      brain_areas_for_analysis: tuple[str]|list[str] = ('HPC', 'ACC'),\n",
    "                      strict_brain_areas: bool = True,\n",
    "                      event_mode: str = 'events',\n",
    "                      filter_low_fr: bool = False,\n",
    "                      get_subspace: bool = False):\n",
    "    \n",
    "    # The df is built on load_sessions.\n",
    "    df = io.load_sessions()\n",
    "    df['session_class'] = {}\n",
    "\n",
    "    # Read session class and store in df.\n",
    "    for task_name in ['pursuit', 'podcast', 'rotations']:\n",
    "        session_infos = io.get_session_names(task_name,\n",
    "                                             brain_areas=['HPC','ACC']) # If the session has recording from HPC or ACC, we read it.\n",
    "        for session_info in session_infos:\n",
    "            S = io.Session(session_info)\n",
    "            try:\n",
    "                S.get_spikes(binsize=bin_size, \n",
    "                             brain_areas_for_analysis=brain_areas_for_analysis, # We can choose which areas to read, HPC, ACC, or both\n",
    "                             strict_brain_areas=strict_brain_areas) # If True, the session has to have all the regions specified in brain_areas_for_analysis.\n",
    "            except ValueError as e:\n",
    "                print(f'Skipping {S.session_key} due to error: {e}')\n",
    "                continue\n",
    "\n",
    "            if filter_low_fr:\n",
    "                S.filter_low_firing_rate()\n",
    "\n",
    "            S.get_events(mode=event_mode, max_gap_dur_secs=max_gap_dur_secs)\n",
    "            S.get_spikes_mu_sd(verbose=VERBOSE)\n",
    "\n",
    "            if get_subspace:\n",
    "                if S.Y_norm.shape[0] > 500: \n",
    "                    # Only compute subspace if there are enough samples.\n",
    "                    # Especially for 'gaps' mode, the number of samples can be very small for the pursuit task. \n",
    "                    S.find_subspace()\n",
    "                else:\n",
    "                    print(f'Skipping {S.session_key} due to missing Y_norm')\n",
    "            df.loc[df.session_key==S.session_key, 'session_class'] = S\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_single_task_df(df_all, task_name: str):\n",
    "\n",
    "    if np.all(pd.isna(df_all.session_class)):\n",
    "        print('Session class not read yet.')\n",
    "        return\n",
    "\n",
    "    print(f'Analyzing {task_name} task sessions...')\n",
    "    df_single = df_all[(df_all.Task==task_name.capitalize()) & ~pd.isna(df_all.session_class)]\n",
    "    j = []\n",
    "    for i in range(len(df_single)):\n",
    "        S = df_single.iloc[i]['session_class']\n",
    "        if np.all(S.spikes_sd == 0):\n",
    "            print(f'Skipping {S.session_key} due to zero spikes_sd')\n",
    "        else:\n",
    "            j.append(i)\n",
    "    print(f'Found {len(df_single)} analyzable {task_name} sessions over {len(np.unique(df_single.Patient))} patients. Found spikes in {len(j)} sessions.')\n",
    "    df_single = df_single.iloc[j]\n",
    "    return df_single\n",
    "\n",
    "def get_single_subj_df(df_all, patient_name: str, verbose=False):\n",
    "    if len(patient_name) > 1:\n",
    "        patient_name = patient_name[-1] # Only taking the last character\n",
    "    if patient_name not in SUBJS:\n",
    "        raise ValueError('Patient name not listed')\n",
    "\n",
    "    df_single = df_all[(df_all.Patient.apply(lambda x: x[-1]) == patient_name) & ~pd.isna(df_all.session_class)]\n",
    "\n",
    "    j = []\n",
    "    for i in range(len(df_single)):\n",
    "        S = df_single.iloc[i]['session_class']\n",
    "        if np.all(S.spikes_sd == 0) and verbose:\n",
    "            print(f'Skipping {S.session_key} due to zero spikes_sd')\n",
    "        else:\n",
    "            j.append(i)\n",
    "\n",
    "    if len(df_single) == 0:\n",
    "        if verbose:\n",
    "            print(f'No recording for patient {patient_name}')\n",
    "        return\n",
    "    else:\n",
    "        if verbose:\n",
    "            print(f'Found {len(df_single)} analyzable sessions in patient {patient_name}. Found spikes in {len(j)} sessions.')\n",
    "        return df_single\n",
    "    \n",
    "def get_paired_df(df_all):\n",
    "\n",
    "    df_paired = []\n",
    "\n",
    "    # make sure fields are valid.\n",
    "    fields = ['Patient','Task','Datetime','session_file','session_class']\n",
    "    if not all([f for f in fields if f in df_all.keys()]):\n",
    "        raise ValueError('Fields should be in {list(df_all.keys())}')\n",
    "\n",
    "    # First find df_single for each subj\n",
    "    for subj in SUBJS:\n",
    "        df_single = df_all[(df_all.Patient.apply(lambda x: x[-1]) == subj) & ~pd.isna(df_all.session_class)]\n",
    "\n",
    "        for i in range(len(df_single)):\n",
    "            for j in range(i, len(df_single)):\n",
    "                task_1 = df_single.iloc[i][fields]\n",
    "                task_2 = df_single.iloc[j][fields]\n",
    "                if np.abs(task_1.Datetime-task_2.Datetime) > pd.Timedelta(hours=30):\n",
    "                    continue\n",
    "                if task_1.Task == task_2.Task:\n",
    "                    continue\n",
    "\n",
    "                # Return 'CS', 'RS', or 'CR' exclusively.\n",
    "                task_pair = ''.join(sorted(list(map(lambda x: TASK_KEY[x.lower()], [task_1.Task,task_2.Task]))))\n",
    "\n",
    "                pair = {'subj': subj, \n",
    "                        'task_pair': task_pair,\n",
    "                        'task_1': task_1.session_class,\n",
    "                        'task_2': task_2.session_class}\n",
    "                \n",
    "                df_paired.append(pair)\n",
    "\n",
    "    df_paired = pd.DataFrame(df_paired)\n",
    "    return df_paired\n",
    "\n",
    "def shuffle_data(arr1, arr2, seed: int = None):\n",
    "    \"\"\"\n",
    "    arr1 (M,N) and arr2 (M,K) are arrays to be concatenated to the first axis.\n",
    "    \"\"\"\n",
    "\n",
    "    if seed is not None:\n",
    "        rng = np.random.default_rng(seed)\n",
    "    else:\n",
    "        rng = np.random.default_rng()\n",
    "\n",
    "    a1, a2 = arr1.copy(), arr2.copy()\n",
    "    A = np.concatenate((a1,a2), axis=0)\n",
    "    inds = rng.permutation(A.shape[0])\n",
    "    A1 = A[inds[:A.shape[0]//2]]\n",
    "    A2 = A[inds[A.shape[0]//2:]]\n",
    "    return (A1, A2)\n",
    "\n",
    "def compute_distances(row, fa_field=\"FA\", ix_field=None, niters_rand=1000, niters_shuf=30, plot_example=False):\n",
    "    \"\"\"Compute true, shuffled, and random geodesic distances for one task pair.\"\"\"\n",
    "\n",
    "    if not hasattr(row.task_1, fa_field) or not hasattr(row.task_2, fa_field):\n",
    "        return {\n",
    "            \"true_dists\": np.nan,\n",
    "            \"shuf_ang_means\": np.nan,\n",
    "            \"rand_ang_means\": np.nan,\n",
    "            \"shuf_dist_means\": np.nan,\n",
    "            \"shuf_dist_stds\": np.nan,\n",
    "            \"rand_dist_means\": np.nan,\n",
    "            \"rand_dist_stds\": np.nan,\n",
    "            \"is_shared\": np.nan,\n",
    "            \"clrs\": np.nan,\n",
    "        }\n",
    "    task1, task2 = row.task_1, row.task_2\n",
    "    sub1, sub2 = getattr(task1, fa_field).subspace, getattr(task2, fa_field).subspace\n",
    "\n",
    "    # true + random angles\n",
    "    ang = subspace.principal_angles(sub1.T, sub2.T)\n",
    "    rand_angles = subspace.rand_principal_angles(sub1.T, sub2.T, niters=niters_rand)\n",
    "\n",
    "    # shuffled angles\n",
    "    shuf_angles = []\n",
    "    for seed in range(niters_shuf):\n",
    "        y1 = task1.Y_norm if ix_field is None else task1.Y_norm[:, getattr(task1, ix_field)]\n",
    "        y2 = task2.Y_norm if ix_field is None else task2.Y_norm[:, getattr(task2, ix_field)]\n",
    "        yshuf1, yshuf2 = shuffle_data(y1, y2, seed=seed)\n",
    "        fashuf1 = io.FactorAnalysisResult(fa.fa_fit(yshuf1, verbose=False))\n",
    "        fashuf2 = io.FactorAnalysisResult(fa.fa_fit(yshuf2, verbose=False))\n",
    "        shuf_angles.append(\n",
    "            subspace.principal_angles(fashuf1.subspace.T, fashuf2.subspace.T)\n",
    "        )\n",
    "\n",
    "    # truncate to shortest angle length\n",
    "    min_len = min(min(map(len, shuf_angles)), len(ang))\n",
    "    shuf_angles = [arr[:min_len] for arr in shuf_angles]\n",
    "\n",
    "    # distances\n",
    "    shuf_dist = np.linalg.norm(shuf_angles, axis=1)\n",
    "    rand_dist = np.linalg.norm(rand_angles, axis=1)\n",
    "    true_dist = np.linalg.norm(ang[:min_len])\n",
    "\n",
    "    if np.sum(true_dist > rand_dist) / len(rand_dist) < 0.001:\n",
    "        is_shared = True\n",
    "    else:\n",
    "        is_shared = False\n",
    "\n",
    "    # Compute normalized angles\n",
    "    \n",
    "    low_bound = np.mean(shuf_angles, axis=0)\n",
    "    up_bound = np.mean(rand_angles, axis=0)\n",
    "    normalized_ang = (ang[:min_len]-low_bound[:min_len]) / (up_bound[:min_len]-low_bound[:min_len])\n",
    "\n",
    "    if plot_example:\n",
    "        plt.figure(figsize=(3,4))\n",
    "        plt.hist(rand_dist, bins=30, color='k', density=True)\n",
    "        plt.hist(shuf_dist, bins=30, color='b', density=True)\n",
    "        plt.axvline(true_dist)\n",
    "        plt.xlabel('Geodesic distance (deg)')\n",
    "        plt.xticks(np.linspace(0,180,5))\n",
    "        plt.title(f'{true_dist:.2f}, rand {np.mean(rand_dist):.2f}±{np.std(rand_dist):.2f}', fontsize=10)\n",
    "        save_plot_dir = os.path.join('plots', 'principal_angles')\n",
    "        if not os.path.exists(save_plot_dir):\n",
    "            os.makedirs(save_plot_dir)\n",
    "        if SAVEFIG:\n",
    "            for ext in ['png','svg']:\n",
    "                plt.savefig(os.path.join(save_plot_dir, f'rand_dist_example.' + ext))\n",
    "        plt.show()\n",
    "\n",
    "    return {\n",
    "        \"true_dists\": true_dist,\n",
    "        \"shuf_ang_means\": np.mean(shuf_angles, axis=0),\n",
    "        \"rand_ang_means\": np.mean(rand_angles, axis=0),\n",
    "        \"shuf_dist_means\": np.mean(shuf_dist),\n",
    "        \"shuf_dist_stds\": np.std(shuf_dist),\n",
    "        \"rand_dist_means\": np.mean(rand_dist),\n",
    "        \"rand_dist_stds\": np.std(rand_dist),\n",
    "        \"clrs\": TASK_PAIRS_CLR[row.task_pair],\n",
    "        \"normalized_ang\": normalized_ang,\n",
    "        \"is_shared\": is_shared,\n",
    "    }\n",
    "\n",
    "def add_distance_metrics(df_pairs, mode=\"both\", niters_rand=1000, niters_shuf=30):\n",
    "    \"\"\"\n",
    "    mode: \"both\" -> use FA (all units),\n",
    "          \"hpc\"  -> use FA_hpc, hpc_ix,\n",
    "          \"acc\"  -> use FA_acc, acc_ix\n",
    "    \"\"\"\n",
    "    mapping = {\n",
    "        \"both\": (\"FA\", None),\n",
    "        \"hpc\":  (\"FA_hpc\", \"hpc_ix\"),\n",
    "        \"acc\":  (\"FA_acc\", \"acc_ix\"),\n",
    "    }\n",
    "    fa_field, ix_field = mapping[mode]\n",
    "\n",
    "    results = df_pairs.apply(\n",
    "        compute_distances,\n",
    "        axis=1,\n",
    "        fa_field=fa_field,\n",
    "        ix_field=ix_field,\n",
    "        niters_rand=niters_rand,\n",
    "        niters_shuf=niters_shuf,\n",
    "    )\n",
    "\n",
    "    return pd.concat([df_pairs.reset_index(drop=True), results.apply(pd.Series)], axis=1)\n",
    "\n",
    "def plot_geodesic_distance(df, region, savefig=False):\n",
    "\n",
    "    plt.figure(figsize=(9,4))\n",
    "    for j in range(3):\n",
    "        plt.subplot(1,3,j+1)\n",
    "        dd = df[df.task_pair == TASK_PAIRS[j]]\n",
    "\n",
    "        compare_shuf = scipy.stats.wilcoxon(dd.true_dists, dd.shuf_dist_means, alternative='greater')\n",
    "        compare_rand = scipy.stats.wilcoxon(dd.true_dists, dd.rand_dist_means, alternative='less')\n",
    "        pval_shuf, pval_rand = compare_shuf[1], compare_rand[1]\n",
    "\n",
    "        for i in range(len(dd)):\n",
    "            plt.scatter([0,1,2],[\n",
    "                dd.iloc[i]['shuf_dist_means'], \n",
    "                dd.iloc[i]['true_dists'], \n",
    "                dd.iloc[i]['rand_dist_means']], ec=dd.iloc[i]['clrs'],s=50, fc='none')\n",
    "            plt.plot([0,1,2],[\n",
    "                dd.iloc[i]['shuf_dist_means'], \n",
    "                dd.iloc[i]['true_dists'], \n",
    "                dd.iloc[i]['rand_dist_means']],c=dd.iloc[i]['clrs'])\n",
    "            plt.errorbar(0, dd.iloc[i]['shuf_dist_means'], yerr=dd.iloc[i]['shuf_dist_stds'], c=dd.iloc[i]['clrs'])\n",
    "            plt.errorbar(2, dd.iloc[i]['rand_dist_means'], yerr=dd.iloc[i]['rand_dist_stds'], c=dd.iloc[i]['clrs'], capsize=0.2)\n",
    "        plt.xticks([0,1,2], ['Shuffle','Data','Random'])\n",
    "        plt.xlim([-0.5,2.5])\n",
    "        plt.yticks([0,90,180,270])\n",
    "        plt.ylabel('Subspace distance (deg)')\n",
    "        plt.title(f'{TASK_PAIRS[j]}\\nshuf {pval_shuf:.2e}\\nrand {pval_rand:.2e}', fontsize=10)\n",
    "    plt.subplots_adjust(wspace=0.5, left=0.1, right=0.9)\n",
    "    save_plot_dir = os.path.join('plots', 'principal_angles')\n",
    "    if not os.path.exists(save_plot_dir):\n",
    "        os.makedirs(save_plot_dir)\n",
    "    if savefig:\n",
    "        for ext in ['png','svg']:\n",
    "            plt.savefig(os.path.join(save_plot_dir, f'subspace_distance_sep_{region}.' + ext))\n",
    "    plt.show()\n",
    "\n",
    "def calc_var_exp(row, n_in_low_group=None):\n",
    "    t1, t2 = row.task_1, row.task_2\n",
    "    if not hasattr(t1, 'FA') or not hasattr(t2, 'FA'):\n",
    "        return {\n",
    "        'vA_max': np.nan, \n",
    "        'vA_low': np.nan, \n",
    "        'vA_high': np.nan, \n",
    "        'vB_max': np.nan, \n",
    "        'vB_low': np.nan, \n",
    "        'vB_high': np.nan\n",
    "    }\n",
    "    A = t1.FA.subspace\n",
    "    B = t2.FA.subspace\n",
    "\n",
    "    # Ua, Ub is the rotation matrix that best aligns subspace A and B\n",
    "    angles, Ua, Ub = subspace.principal_angles(A.T, B.T, return_vectors=True)\n",
    "    Ub = Ub.T\n",
    "\n",
    "    varA   = np.var(t1.Y_norm @ A.T, axis=0)\n",
    "    varA_p = np.var(t1.Y_norm @ A.T @ Ua, axis=0)\n",
    "    varB   = np.var(t2.Y_norm @ B.T, axis=0)\n",
    "    varB_p = np.var(t2.Y_norm @ B.T @ Ub, axis=0)\n",
    "\n",
    "    n_in_low_group = n_in_low_group or len(angles) // 2\n",
    "\n",
    "    # Trim arrays if needed\n",
    "    total = 2 * n_in_low_group\n",
    "    if total < len(angles):\n",
    "        varA_p = varA_p[:total]\n",
    "        varB_p = varB_p[:total]\n",
    "        assert len(varA_p) == total\n",
    "\n",
    "    return {\n",
    "        'vA_max': np.sum(varA[:n_in_low_group]) / np.sum(varA), \n",
    "        'vA_low': np.sum(varA_p[:n_in_low_group]) / np.sum(varA), \n",
    "        'vA_high': np.sum(varA_p[n_in_low_group:]) / np.sum(varA), \n",
    "        'vB_max': np.sum(varB[:n_in_low_group]) / np.sum(varB), \n",
    "        'vB_low': np.sum(varB_p[:n_in_low_group]) / np.sum(varB), \n",
    "        'vB_high': np.sum(varB_p[n_in_low_group:]) / np.sum(varB)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31359a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read all sessions\n",
    "df_singles = read_all_sessions(max_gap_dur_secs=1, bin_size=50, \n",
    "                               strict_brain_areas=False, event_mode='events', \n",
    "                               get_subspace=True, filter_low_fr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92815ac4",
   "metadata": {
    "title": "Plot firing rates, separating brain regions"
   },
   "outputs": [],
   "source": [
    "## Figure 2. Panel F, G, and H.\n",
    "\n",
    "plt.figure(figsize=(len(TASK_PAIRS)*4,4))\n",
    "for area in ['HPC','ACC']:\n",
    "\n",
    "    df_singles = read_all_sessions(max_gap_dur_secs=1, bin_size=50, strict_brain_areas=False,\n",
    "                                   brain_areas_for_analysis=[area])\n",
    "    \n",
    "    df_pairs = get_paired_df(df_singles)\n",
    "    for k, pair_name in enumerate(TASK_PAIRS):\n",
    "        plt.subplot(1,len(TASK_PAIRS),k+1)\n",
    "        pairs = df_pairs[df_pairs.task_pair == pair_name]\n",
    "        for i in range(len(pairs)):\n",
    "            s1, s2 = pairs.iloc[i].task_1, pairs.iloc[i].task_2\n",
    "            plt.scatter(s1.spikes_mu, s2.spikes_mu, s=25, ec=AREA_CLR[area], fc='none', lw=1, marker='o')\n",
    "        plt.xscale('log')\n",
    "        plt.yscale('log')\n",
    "        plt.xlabel(f'{s1.task} FR')\n",
    "        plt.ylabel(f'{s2.task} FR')\n",
    "        plt.title(pair_name)\n",
    "        plt.plot([0.5,50],[0.5,50], ls='--', c='k')\n",
    "plt.subplots_adjust(left=0.1,right=0.9,bottom=0.2,wspace=0.5)\n",
    "\n",
    "save_plot_dir = os.path.join('plots', 'general_plots')\n",
    "if not os.path.exists(save_plot_dir):\n",
    "    os.makedirs(save_plot_dir)\n",
    "if SAVEFIG:\n",
    "    for ext in ['png','svg']:\n",
    "        plt.savefig(os.path.join(save_plot_dir, 'firing_rates_show-areas.' + ext))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f7c76c",
   "metadata": {
    "title": "Plot shared dimensionality for all patients of all tasks"
   },
   "outputs": [],
   "source": [
    "## Figure 3. Panel C, D, and E.\n",
    "\n",
    "n_units = df_singles['session_class'].apply(lambda s: s.FA.n_components)\n",
    "d_shared = df_singles['session_class'].apply(lambda s: s.FA.d_shared)\n",
    "\n",
    "res = scipy.stats.linregress(n_units, d_shared)\n",
    "pearsonr = res.rvalue\n",
    "n_sample = len(n_units)\n",
    "x_range = np.array([np.min(n_units)-2, np.max(n_units)+2])\n",
    "\n",
    "plt.figure(figsize=(2,4))\n",
    "for pair, value in collections.Counter(list(zip(n_units, d_shared))).items():\n",
    "    plt.scatter(*pair, s=value*15, ec='k',fc='none', lw=1)\n",
    "\n",
    "plt.plot(x_range, x_range*res.slope+res.intercept,ls='--', c='k', lw=1)\n",
    "plt.ylim([0,14])\n",
    "plt.xlabel('n_units')\n",
    "plt.ylabel('d_shared')\n",
    "plt.title(f'Pearson R = {pearsonr:.3f}, N={n_sample}', fontsize=10)\n",
    "plt.subplots_adjust(bottom=0.1, left=0.1, right=0.9, top=0.8)\n",
    "save_plot_dir = os.path.join('plots', 'general_plots')\n",
    "if not os.path.exists(save_plot_dir):\n",
    "    os.makedirs(save_plot_dir)\n",
    "if SAVEFIG:\n",
    "    for ext in ['png','svg']:\n",
    "        plt.savefig(os.path.join(save_plot_dir, 'd_shared_n_units.' + ext))\n",
    "plt.show()\n",
    "\n",
    "code = dict(zip(TASK_NAMES, [0,1,2]))\n",
    "dfs = df_singles[['Patient','Task','session_class']]\n",
    "dfs['d_shared'] = df_singles['session_class'].apply(lambda s: s.FA.d_shared)\n",
    "dfs['task_code'] = dfs['Task'].str.lower().apply(lambda x: code[x])\n",
    "\n",
    "range_array = []\n",
    "for j in range(len(SUBJS)):\n",
    "    dd = get_single_subj_df(dfs, SUBJS[j])\n",
    "    range_array.append(dd.d_shared.max() - dd.d_shared.min())\n",
    "\n",
    "\n",
    "fig,ax = plt.subplots(1,1,figsize=(2,4))\n",
    "sns.scatterplot(data=dfs, x='task_code', y='d_shared',ax=ax, color='k')\n",
    "for j in range(len(SUBJS)):\n",
    "    dd = get_single_subj_df(dfs, SUBJS[j])\n",
    "    \n",
    "    for i in range(len(dd) - 1):\n",
    "        xs = (dd.iloc[i]['task_code'], dd.iloc[i+1]['task_code'])\n",
    "        ys = (dd.iloc[i]['d_shared'], dd.iloc[i+1]['d_shared'])\n",
    "        ax.plot(xs, ys, c='k', ls='-', lw=0.5)\n",
    "plt.xticks([0,1,2],TASK_NAMES)\n",
    "plt.xlim([-0.5,2.5])\n",
    "plt.title(f'Range {np.mean(range_array):.3f} $\\pm$ {np.std(range_array):.3f}', fontsize=10)\n",
    "plt.subplots_adjust(bottom=0.1, left=0.1, right=0.9, top=0.8)\n",
    "plt.ylim([0,14])\n",
    "save_plot_dir = os.path.join('plots', 'general_plots')\n",
    "if not os.path.exists(save_plot_dir):\n",
    "    os.makedirs(save_plot_dir)\n",
    "if SAVEFIG:\n",
    "    for ext in ['png','svg']:\n",
    "        plt.savefig(os.path.join(save_plot_dir, 'd_shared_per_session.' + ext))\n",
    "plt.show()\n",
    "\n",
    "n_units = df_singles['session_class'].apply(lambda s: s.FA.n_components)\n",
    "d_shared = df_singles['session_class'].apply(lambda s: s.FA.d_shared)\n",
    "df = pd.DataFrame({'ratio': n_units/d_shared, 'task': df_singles.Task.str.lower()})\n",
    "res = scipy.stats.kruskal(\n",
    "    df[df.task=='podcast'].ratio,\n",
    "    df[df.task=='pursuit'].ratio,\n",
    "    df[df.task=='rotations'].ratio)\n",
    "\n",
    "fig,ax = plt.subplots(1,1,figsize=(2,4))\n",
    "sns.barplot(data=df, x='task',y='ratio', capsize=0.1, ax=ax, palette=TASK_CLR)\n",
    "plt.ylabel('Ratio of # units to d-shared')\n",
    "plt.title(f'KW test, stats: {res.statistic:.3f}, pval: {res.pvalue:.3f}')\n",
    "\n",
    "save_plot_dir = os.path.join('plots', 'general_plots')\n",
    "if not os.path.exists(save_plot_dir):\n",
    "    os.makedirs(save_plot_dir)\n",
    "if SAVEFIG:\n",
    "    for ext in ['png','svg']:\n",
    "        plt.savefig(os.path.join(save_plot_dir, 'd_shared_ratio_per_task.' + ext))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c8f168",
   "metadata": {
    "title": "Plot shared variance per unit"
   },
   "outputs": [],
   "source": [
    "## Figure 3. Panel F.\n",
    "\n",
    "df_singles = read_all_sessions(max_gap_dur_secs=1, bin_size=50, \n",
    "                               strict_brain_areas=False, event_mode='events', \n",
    "                               get_subspace=True, filter_low_fr=False)\n",
    "subj_complete_all_tasks = 'XZAD' \n",
    "\n",
    "# There are four subjects that finished all three tasks.\n",
    "# The example patient in the paper is X.\n",
    "plt.figure(figsize=(10,3))\n",
    "for i in range(len(subj_complete_all_tasks)):\n",
    "    df_three_task = df_singles[df_singles.Patient.apply(lambda x: x[-1]) == subj_complete_all_tasks[i]]\n",
    "    plt.subplot(1,len(subj_complete_all_tasks),i+1)\n",
    "    for j in range(len(df_three_task)):\n",
    "        s = df_three_task.iloc[j].session_class\n",
    "        s.find_subspace()\n",
    "        \n",
    "        # Scatter plot \n",
    "        # plt.scatter(range(len(s.channels)), s.FA.shared_var_per_unit*100, c=TASK_CLR[s.task], s=5)\n",
    "        \n",
    "        # Line plot\n",
    "        plt.plot(s.FA.shared_var_per_unit*100,  c=TASK_CLR[s.task])\n",
    "    plt.xlabel('Unit number')\n",
    "    plt.ylabel('% shared variance')\n",
    "    plt.title(subj_complete_all_tasks[i])\n",
    "plt.subplots_adjust(left=0.1,right=0.9,bottom=0.2,wspace=0.5)\n",
    "\n",
    "save_plot_dir = os.path.join('plots', 'general_plots')\n",
    "if not os.path.exists(save_plot_dir):\n",
    "    os.makedirs(save_plot_dir)\n",
    "if SAVEFIG:\n",
    "    for ext in ['png','svg']:\n",
    "        plt.savefig(os.path.join(save_plot_dir, 'shared_var_per_unit.' + ext))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d456df35",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "Plot shared var per unit for all patients of all tasks"
   },
   "outputs": [],
   "source": [
    "## Figure 3. Panel G, H, and I.\n",
    "df_pairs = get_paired_df(df_singles)\n",
    "\n",
    "for j in range(len(TASK_PAIRS)):\n",
    "    df_pair = df_pairs[df_pairs.task_pair == TASK_PAIRS[j]]\n",
    "\n",
    "    plt.figure(figsize=(3,3))\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(df_pair)):\n",
    "        df = df_pair.iloc[i]\n",
    "        x = df.task_1.FA.shared_var_per_unit\n",
    "        y = df.task_2.FA.shared_var_per_unit\n",
    "        plt.scatter(x*100, y*100, ec='k', fc='none', s=10, alpha=0.4)\n",
    "        xs.append(x); ys.append(y)\n",
    "\n",
    "    xs = np.hstack(xs); ys = np.hstack(ys)\n",
    "    res = pg.ttest(xs,ys, paired=True)\n",
    "    stats = res.iloc[0]['T']\n",
    "    pval = res.iloc[0]['p-val']\n",
    "    dof = res.iloc[0]['dof']\n",
    "    cohen = res.iloc[0]['cohen-d']\n",
    "\n",
    "    plt.xlabel(df.task_1.task + ' (%)')\n",
    "    plt.ylabel(df.task_2.task + ' (%)')\n",
    "    # plt.xticks(np.linspace(0,100,6)); plt.yticks(np.linspace(0,100,6))\n",
    "    plt.plot([0.1,100],[0.1,100],ls='--',c='k',lw=1)\n",
    "    plt.title(f't({dof})={stats:.3f}, p={pval:.3e}, D={cohen:.3f}', fontsize=10)\n",
    "    plt.subplots_adjust(left=0.2,right=0.8, bottom=0.2)\n",
    "    save_plot_dir = os.path.join('plots', 'general_plots')\n",
    "    if not os.path.exists(save_plot_dir):\n",
    "        os.makedirs(save_plot_dir)\n",
    "    if SAVEFIG:\n",
    "        for ext in ['png','svg']:\n",
    "            plt.savefig(os.path.join(save_plot_dir, f'shared_var_per_unit_paired_{j+1}.' + ext))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dede028",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Figure 4. Panel A, B, and C.\n",
    "plt.figure(figsize=(8,3))\n",
    "for j in range(len(TASK_NAMES)):\n",
    "    plt.subplot(1,3,j+1)\n",
    "    dfs = get_single_task_df(df_singles[(df_singles['Patient']!='YEY')&(df_singles['Patient']!='YEZ')], TASK_NAMES[j])\n",
    "    hpc, acc = [], []\n",
    "    for i in range(len(dfs)):\n",
    "        s = dfs.iloc[i].session_class\n",
    "        hpc.extend(s.FA.shared_var_per_unit[s.hpc_ix])\n",
    "        acc.extend(s.FA.shared_var_per_unit[s.acc_ix])\n",
    "\n",
    "    res = pg.ttest(hpc,acc, paired=False, alternative='greater')\n",
    "    stats = res.iloc[0]['T']\n",
    "    pval = res.iloc[0]['p-val']\n",
    "    dof = res.iloc[0]['dof']\n",
    "\n",
    "    plt.hist(hpc, bins=np.linspace(0,1,21), color=AREA_CLR['HPC'], alpha=0.5, edgecolor='k', density=True, label='HPC')\n",
    "    plt.hist(acc, bins=np.linspace(0,1,21), color=AREA_CLR['ACC'], alpha=0.5, edgecolor='k', density=True, label='ACC')\n",
    "    plt.axvline(np.median(hpc), ls='--',c=AREA_CLR['HPC'])\n",
    "    plt.axvline(np.median(acc), ls='--',c=AREA_CLR['ACC'])\n",
    "    plt.title(f'{TASK_NAMES[j]}\\nt({dof:.2f})={stats:.3f}, p={pval:.2e}', fontdict={'size': 10})\n",
    "    plt.xlabel('Shared variance per unit')\n",
    "    plt.ylabel('Density')\n",
    "    plt.legend(frameon=False)\n",
    "plt.subplots_adjust(wspace=0.5,left=0.15,right=0.9,bottom=0.15)\n",
    "save_plot_dir = os.path.join('plots', 'regional_difference')\n",
    "if not os.path.exists(save_plot_dir):\n",
    "    os.makedirs(save_plot_dir)\n",
    "if SAVEFIG:\n",
    "    for ext in ['png','svg']:\n",
    "        plt.savefig(os.path.join(save_plot_dir, 'shared_var_per_unit_per_task.' + ext))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1feb8790",
   "metadata": {
    "title": "[NOT USEFUL] Plot factor 1 coefficients of each patient"
   },
   "outputs": [],
   "source": [
    "## Figure 5. Panel A.\n",
    "# We are showing the result patient X, excluding one of repeated session from Pursuit (blue).\n",
    "plt.figure(figsize=(12,10))\n",
    "for j in range(len(SUBJS)):\n",
    "    df = get_single_subj_df(df_singles, SUBJS[j])\n",
    "    \n",
    "    plt.subplot(3,4,j+1)\n",
    "    for i in range(len(df)):\n",
    "        s = df.iloc[i].session_class\n",
    "        plt.plot(s.FA.subspace[0], c=TASK_CLR[s.task])\n",
    "    plt.title(s.subj)\n",
    "    plt.ylabel('First factor coefficient')\n",
    "    plt.xlabel('Unit number')\n",
    "plt.subplots_adjust(hspace=0.4,wspace=0.4, bottom=0.1, left=0.1, right=0.9)\n",
    "save_plot_dir = os.path.join('plots', 'general_plots')\n",
    "if not os.path.exists(save_plot_dir):\n",
    "    os.makedirs(save_plot_dir)\n",
    "if SAVEFIG:\n",
    "    for ext in ['png','svg']:\n",
    "        plt.savefig(os.path.join(save_plot_dir, 'first_factor_coeff.' + ext))\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d780dd8",
   "metadata": {
    "title": "Regional difference - shared var per dim"
   },
   "outputs": [],
   "source": [
    "## Figure 4. Panel D, E, and F.\n",
    "\n",
    "hpc_powers = collections.defaultdict(list)\n",
    "for j in range(len(TASK_NAMES)):\n",
    "    dfs = get_single_task_df(df_singles[(df_singles['Patient']!='YEY')&(df_singles['Patient']!='YEZ')],TASK_NAMES[j])\n",
    "    for i in range(len(dfs)):\n",
    "        s = dfs.iloc[i].session_class\n",
    "        total_var_per_unit_per_dim = (s.FA.subspace)**2 # (d, N)\n",
    "        hpc_powers[TASK_NAMES[j]].extend(total_var_per_unit_per_dim[:, s.hpc_ix].sum(axis=1))\n",
    "\n",
    "plt.figure(figsize=(9,3))\n",
    "for j in range(len(TASK_NAMES)):\n",
    "    hpc_power = hpc_powers[TASK_NAMES[j]]\n",
    "    hpc_stats = scipy.stats.wilcoxon(hpc_power, 0.5, alternative='greater')\n",
    "    a0, b0, _, _ = scipy.stats.beta.fit(hpc_power, floc=0, fscale=1)\n",
    "\n",
    "    x = np.linspace(0, 1, 500)\n",
    "    pdf_values = scipy.stats.beta.pdf(x, a0, b0)\n",
    "    plt.subplot(1,3,j+1)\n",
    "    plt.hist(hpc_power, bins=np.linspace(0,1,21), density=True)\n",
    "    plt.plot(x, pdf_values, c='k', label=f'a={a0:.2f}, b={b0:.2f}')\n",
    "    plt.ylabel('Density')\n",
    "    plt.xlabel('HPC $\\%$sv in each dim')\n",
    "    plt.title(f'{TASK_NAMES[j]}, \\nW={hpc_stats.statistic}, p={hpc_stats.pvalue:.2e}, n={len(hpc_power)}',fontsize=10)\n",
    "    plt.legend(frameon=False)\n",
    "plt.subplots_adjust(wspace=0.6, bottom=0.3)\n",
    "save_plot_dir = os.path.join('plots', 'regional_difference')\n",
    "if not os.path.exists(save_plot_dir):\n",
    "    os.makedirs(save_plot_dir)\n",
    "if SAVEFIG:\n",
    "    for ext in ['png','svg']:\n",
    "        plt.savefig(os.path.join(save_plot_dir, f'hpc_sv_density.' + ext))\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(4,5))\n",
    "for  j in range(len(TASK_NAMES)):\n",
    "    data = hpc_powers[TASK_NAMES[j]]\n",
    "    n_boot = 3000\n",
    "    rng = np.random.default_rng()\n",
    "    n = len(data)\n",
    "    a0, b0, _, _ = scipy.stats.beta.fit(data, floc=0, fscale=1)\n",
    "    boots = np.empty((n_boot, 2))\n",
    "    for i in range(n_boot):\n",
    "        resamp = rng.choice(data, size=n, replace=True)\n",
    "        ai, bi, _, _ = scipy.stats.beta.fit(resamp, floc=0, fscale=1)\n",
    "        boots[i, :] = (ai, bi)\n",
    "\n",
    "    beta_stats = pg.ttest(boots[:,0], boots[:,1], paired=True, alternative='greater')\n",
    "    pval = beta_stats['p-val'].iloc[0]\n",
    "    tval = beta_stats['T'].iloc[0]\n",
    "    dof = beta_stats['dof'].iloc[0]\n",
    "    plt.boxplot(boots, whis=(2.5,97.5), showfliers=False, positions=[j*2, j*2+1])\n",
    "    plt.text(-0.2, 1.3-j*0.06, f'{TASK_NAMES[j]}, t({dof})={tval:.2f}, p={pval})', fontsize=10)\n",
    "plt.ylim([0.2,1.4])\n",
    "plt.ylabel('Bootstrap estimates')\n",
    "plt.xlabel('a (left) and b (right) per task, (C,S,R)')\n",
    "plt.subplots_adjust(left=0.2, right=0.9, bottom=0.2, top=0.8)\n",
    "save_plot_dir = os.path.join('plots', 'regional_difference')\n",
    "if not os.path.exists(save_plot_dir):\n",
    "    os.makedirs(save_plot_dir)\n",
    "if SAVEFIG:\n",
    "    for ext in ['png','svg']:\n",
    "        plt.savefig(os.path.join(save_plot_dir, f'hpc_sv_betas.' + ext))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7325c575",
   "metadata": {
    "title": "Regional difference - FA on one vs both regions"
   },
   "outputs": [],
   "source": [
    "## Figure 4. Panel G, H, and I.\n",
    "dfs = df_singles[(df_singles.Patient!='YEY')&(df_singles.Patient!='YEZ')]\n",
    "hpc_diffs, acc_diffs = [], []\n",
    "for j in range(len(TASK_NAMES)):\n",
    "    df = get_single_task_df(dfs, TASK_NAMES[j])\n",
    "\n",
    "    hpc_svpu, acc_svpu, hpc_svpu_add, acc_svpu_add = [], [] ,[] ,[]\n",
    "    hpc_diff, acc_diff = [], []\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        print(f'{i} out of {len(df)} sessions in {TASK_NAMES[j]}')\n",
    "        s = df.iloc[i].session_class\n",
    "        Y = s.Y_norm\n",
    "\n",
    "        # Fit FA for each region and both regions\n",
    "        FA_hpc = io.FactorAnalysisResult(fa.fa_fit(\n",
    "            Y[:, s.hpc_ix], cv_components=np.arange(Y.shape[1]), max_iter=int(1e5)))\n",
    "        FA_acc = io.FactorAnalysisResult(fa.fa_fit(\n",
    "            Y[:, s.acc_ix], cv_components=np.arange(Y.shape[1]), max_iter=int(1e5)))\n",
    "        FA_all = io.FactorAnalysisResult(fa.fa_fit(\n",
    "            Y, cv_components=np.arange(Y.shape[1]), max_iter=int(1e5)))\n",
    "\n",
    "        # Store shared var per unit\n",
    "        hpc_svpu.extend(FA_hpc.shared_var_per_unit) # HPC's sv per unit (svpu) when fitting HPC only\n",
    "        acc_svpu.extend(FA_acc.shared_var_per_unit) # ACC's svpu when fitting ACC only\n",
    "        hpc_svpu_add.extend(FA_all.shared_var_per_unit[s.hpc_ix]) # HPC's svpu when fitting both regions\n",
    "        acc_svpu_add.extend(FA_all.shared_var_per_unit[s.acc_ix]) # ACC's svpu when fitting both regions\n",
    "\n",
    "        # Also store the difference\n",
    "        hpc_diff.extend(FA_all.shared_var_per_unit[s.hpc_ix] - FA_hpc.shared_var_per_unit)\n",
    "        acc_diff.extend(FA_all.shared_var_per_unit[s.acc_ix] - FA_acc.shared_var_per_unit)\n",
    "\n",
    "    hpc_diffs.extend(hpc_diff)\n",
    "    acc_diffs.extend(acc_diff)\n",
    "    \n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.scatter(hpc_svpu, hpc_svpu_add, s=10, ec=AREA_CLR['HPC'], fc='none')\n",
    "    plt.scatter(acc_svpu, acc_svpu_add, s=10, ec=AREA_CLR['ACC'], fc='none')\n",
    "    plt.xlabel('sv per unit, fitting single region')\n",
    "    plt.ylabel('sv per unit, fitting both regions')\n",
    "    plt.plot([1e-2,1],[1e-2,1], c='k', ls='--', alpha=0.4)\n",
    "    plt.title(f'{TASK_NAMES[j]}, thres=CV')\n",
    "    # plt.xscale('log')\n",
    "    # plt.yscale('log')\n",
    "    plt.subplots_adjust(left=0.2, right=0.8, top=0.8, bottom=0.2)\n",
    "\n",
    "    save_plot_dir = os.path.join('plots', 'regional_difference', 'one_vs_both_regions')\n",
    "    if not os.path.exists(save_plot_dir):\n",
    "        os.makedirs(save_plot_dir)\n",
    "    if SAVEFIG:\n",
    "        for ext in ['png','svg']:\n",
    "            plt.savefig(os.path.join(save_plot_dir, f'{TASK_NAMES[j]}_cv.' + ext))\n",
    "    plt.show()\n",
    "\n",
    "    stats, pval = scipy.stats.ttest_1samp(acc_diff, 0, alternative='greater')\n",
    "    acc_info = f'ACC: t({len(acc_diff)-1})={stats:.3f}, p={pval:.2e}'\n",
    "    stats, pval = scipy.stats.ttest_1samp(hpc_diff, 0, alternative='greater')\n",
    "    hpc_info = f'HPC: t({len(hpc_diff)-1})={stats:.3f}, p={pval:.2e}'\n",
    "    stats, pval = scipy.stats.ttest_ind(acc_diff, hpc_diff, alternative='greater')\n",
    "    diff_info = f'∆: t({len(hpc_diff)+len(acc_diff)-2})={stats:.3f}, p={pval:.2e}'\n",
    "    fig, ax = plt.subplots(1,1,figsize=(4,4))\n",
    "    sns.kdeplot(hpc_diff, ax=ax,color=AREA_CLR['HPC'])\n",
    "    sns.kdeplot(acc_diff, ax=ax,color=AREA_CLR['ACC'])\n",
    "    ax.set_xlim([-0.3,0.3])\n",
    "\n",
    "    ax.set_title(f'{hpc_info}\\n{acc_info}\\n{diff_info}', fontsize=10)\n",
    "    ax.set_xlabel('∆ shared var')\n",
    "    ax.set_ylabel('Density')\n",
    "    plt.subplots_adjust(left=0.2, right=0.8, top=0.7, bottom=0.2)\n",
    "\n",
    "    save_plot_dir = os.path.join('plots', 'regional_difference', 'one_vs_both_regions')\n",
    "    if not os.path.exists(save_plot_dir):\n",
    "        os.makedirs(save_plot_dir)\n",
    "    if SAVEFIG:\n",
    "        for ext in ['png','svg']:\n",
    "            plt.savefig(os.path.join(save_plot_dir, f'{TASK_NAMES[j]}_diff_cv.' + ext))\n",
    "    plt.show()\n",
    "\n",
    "stats, pval = scipy.stats.ttest_1samp(acc_diffs, 0, alternative='greater')\n",
    "acc_info = f'ACC: t({len(acc_diffs)-1})={stats:.3f}, p={pval:.2e}'\n",
    "stats, pval = scipy.stats.ttest_1samp(hpc_diffs, 0, alternative='greater')\n",
    "hpc_info = f'HPC: t({len(hpc_diffs)-1})={stats:.3f}, p={pval:.2e}'\n",
    "stats, pval = scipy.stats.ttest_ind(acc_diffs, hpc_diffs, alternative='greater')\n",
    "diff_info = f'∆: t({len(hpc_diffs)+len(acc_diffs)-2})={stats:.3f}, p={pval:.2e}'\n",
    "fig, ax = plt.subplots(1,1,figsize=(4,4))\n",
    "sns.kdeplot(hpc_diffs, ax=ax,color=AREA_CLR['HPC'])\n",
    "sns.kdeplot(acc_diffs, ax=ax,color=AREA_CLR['ACC'])\n",
    "\n",
    "ax.set_xlim([-0.4,0.4])\n",
    "ax.set_title(f'{hpc_info}\\n{acc_info}\\n{diff_info}', fontsize=10)\n",
    "ax.set_xlabel('∆ shared var')\n",
    "ax.set_ylabel('Density')\n",
    "plt.subplots_adjust(left=0.2, right=0.8, top=0.7, bottom=0.2)\n",
    "\n",
    "save_plot_dir = os.path.join('plots', 'regional_difference', 'one_vs_both_regions')\n",
    "if not os.path.exists(save_plot_dir):\n",
    "    os.makedirs(save_plot_dir)\n",
    "if SAVEFIG:\n",
    "    for ext in ['png','svg']:\n",
    "        plt.savefig(os.path.join(save_plot_dir, f'diff_cv_ALL.' + ext))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f761fd53",
   "metadata": {
    "title": "Plot principal angles"
   },
   "outputs": [],
   "source": [
    "## Figure 5. Panel B. Use i=3 for the example in the paper. \n",
    "for i in range(len(df_pairs)):\n",
    "    # Chosen one: i=3 or i=13\n",
    "    row = df_pairs.iloc[i]\n",
    "    task1, task2 = row.task_1, row.task_2\n",
    "    sub1, sub2 = task1.FA.subspace, task2.FA.subspace\n",
    "    ang = subspace.principal_angles(sub1.T, sub2.T)\n",
    "    rand_angles = subspace.rand_principal_angles(sub1.T, sub2.T, niters=100)\n",
    "\n",
    "    shuf_angles = []\n",
    "    for it in range(30):\n",
    "        (yshuf1, yshuf2) = shuffle_data(task1.Y_norm, task2.Y_norm, seed=it)\n",
    "        fashuf1 = io.FactorAnalysisResult(fa.fa_fit(yshuf1, verbose=False))\n",
    "        fashuf2 = io.FactorAnalysisResult(fa.fa_fit(yshuf2, verbose=False))\n",
    "        shuf_angles.append(subspace.principal_angles(fashuf1.subspace.T, fashuf2.subspace.T))\n",
    "\n",
    "    # Trim shuffle angles\n",
    "    min_len = min(list(map(len, shuf_angles)))\n",
    "    min_len = np.min((min_len, len(ang)))\n",
    "    shuf_angles = [elem[:min_len] for elem in shuf_angles]\n",
    "    assert np.min(list(map(len, shuf_angles)))==np.max(list(map(len, shuf_angles))), ValueError('Shuffle angles with different length, cannot average')\n",
    "\n",
    "    rand_mean = np.mean(rand_angles, axis=0)\n",
    "    rand_std = np.std(rand_angles, axis=0)\n",
    "    shuf_mean = np.mean(shuf_angles, axis=0)\n",
    "    shuf_std = np.std(shuf_angles, axis=0)\n",
    "\n",
    "    plt.figure(figsize=(3,4))\n",
    "    plt.scatter(range(len(ang)), ang, c='k', marker='o', s=15)\n",
    "    plt.plot(range(len(ang)), ang, c='k')\n",
    "    plt.scatter(range(len(ang)), rand_mean, c='gray', marker='o', s=15)\n",
    "    plt.plot(range(len(ang)), rand_mean, c='gray')\n",
    "    plt.fill_between(range(len(rand_mean)), rand_mean-rand_std, rand_mean+rand_std, color='gray', alpha=0.3)\n",
    "    plt.scatter(range(len(shuf_mean)), shuf_mean, c='gray', marker='o', s=15)\n",
    "    plt.plot(range(len(shuf_mean)), shuf_mean, c='gray', ls='--')\n",
    "    plt.fill_between(range(len(shuf_mean)), shuf_mean-shuf_std, shuf_mean+shuf_std, color='gray', alpha=0.3)\n",
    "    plt.title(f'{task1}, {task2}', fontsize=10)\n",
    "    plt.ylim([-5,95])\n",
    "    plt.yticks(np.linspace(0,90,4))\n",
    "    plt.xticks(np.arange(len(ang)), np.arange(len(ang))+1)\n",
    "    plt.xlabel('Principal angle index')\n",
    "    plt.ylabel('Angle (deg)')\n",
    "    plt.subplots_adjust(left=0.2,right=0.8, bottom=0.2, top=0.8)\n",
    "    save_plot_dir = os.path.join('plots', 'principal_angles')\n",
    "    if not os.path.exists(save_plot_dir):\n",
    "        os.makedirs(save_plot_dir)\n",
    "    if SAVEFIG:\n",
    "        for ext in ['png','svg']:\n",
    "            plt.savefig(os.path.join(save_plot_dir, f'principal_ang_example_{i}.' + ext))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413375b7",
   "metadata": {
    "title": "Plot normalized principal angles"
   },
   "outputs": [],
   "source": [
    "## Figure 5. Panel C. and Figure S5.\n",
    "df_pairs_both = add_distance_metrics(df_pairs, mode=\"both\", niters_rand=100, niters_shuf=30)\n",
    "row = df_pairs_both.iloc[3]\n",
    "res = compute_distances(row)\n",
    "\n",
    "sub1, sub2 = row.task_1.FA.subspace, row.task_2.FA.subspace\n",
    "rand_angles = subspace.rand_principal_angles(sub1.T, sub2.T, niters=1000)\n",
    "\n",
    "plt.figure(figsize=(2,3))\n",
    "\n",
    "plt.plot(res['normalized_ang'], c='k')\n",
    "plt.xlabel('Principal angle index')\n",
    "plt.ylabel('Normalized principal angles')\n",
    "plt.axhline(0.1, c='r', ls='--', lw=1)\n",
    "plt.ylim([0,1])\n",
    "save_plot_dir = os.path.join('plots', 'principal_angles')\n",
    "if not os.path.exists(save_plot_dir):\n",
    "    os.makedirs(save_plot_dir)\n",
    "if SAVEFIG:\n",
    "    for ext in ['png','svg']:\n",
    "        plt.savefig(os.path.join(save_plot_dir, f'normalized_principal_ang.' + ext))\n",
    "plt.show()\n",
    "\n",
    "compute_distances(row, plot_example=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625a5553",
   "metadata": {
    "lines_to_next_cell": 2,
    "title": "Plot fraction of dimensions shared"
   },
   "outputs": [],
   "source": [
    "## Figure 5. Panel D.\n",
    "res = []\n",
    "for i in range(len(df_pairs_both)):\n",
    "    ang = df_pairs_both.iloc[i]['normalized_ang']\n",
    "    res.append((ang<0.5).sum()/len(ang))\n",
    "\n",
    "df_pairs_both['frac_shared'] = res\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(3,4))\n",
    "sns.stripplot(data=df_pairs_both, x='task_pair', y='frac_shared', palette=TASK_PAIRS_CLR, size=5, ax=ax,linewidth=1)\n",
    "sns.barplot(data=df_pairs_both, x='task_pair', y='frac_shared', capsize=0.1, errorbar='se',ax=ax,facecolor='w',edgecolor='k',errwidth=1)\n",
    "ax.set_ylabel('Fraction of shared dimensions')\n",
    "ax.set_title(f'{df_pairs_both['frac_shared'].mean():.4f} ± {df_pairs_both['frac_shared'].std():.4f} (mean ± SD)', fontsize=10)\n",
    "fig.subplots_adjust(left=0.2,right=0.8, bottom=0.2, top=0.8)\n",
    "save_plot_dir = os.path.join('plots', 'principal_angles')\n",
    "if not os.path.exists(save_plot_dir):\n",
    "    os.makedirs(save_plot_dir)\n",
    "if SAVEFIG:\n",
    "    for ext in ['png','svg']:\n",
    "        plt.savefig(os.path.join(save_plot_dir, f'fraction_of_dimensions_shared.' + ext))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bde1e0",
   "metadata": {
    "lines_to_next_cell": 2,
    "title": "Plot subspace alignment"
   },
   "outputs": [],
   "source": [
    "## Figure 6. Panel B.\n",
    "\n",
    "df_pairs = get_paired_df(df_singles)\n",
    "plt.figure(figsize=(9,4))\n",
    "for j in range(3):\n",
    "    plt.subplot(1,3,j+1)\n",
    "    df_pair = df_pairs[df_pairs.task_pair == TASK_PAIRS[j]]\n",
    "    results = df_pair.reset_index(drop=True).apply(calc_var_exp, axis=1)\n",
    "    df_pair = pd.concat([df_pair.reset_index(drop=True), results.apply(pd.Series)], axis=1)\n",
    "    plt.errorbar([0,1,2], [df_pair.vA_max.mean(), df_pair.vA_low.mean(), df_pair.vA_high.mean()], \n",
    "                 yerr=[df_pair.vA_max.std(), df_pair.vA_low.std(), df_pair.vA_high.std()], \n",
    "                 c=TASK_CLR[df_pair.iloc[0].task_1.task], marker='o', capsize=5)\n",
    "    plt.errorbar([0,1,2], [df_pair.vB_max.mean(), df_pair.vB_low.mean(), df_pair.vB_high.mean()], \n",
    "                 yerr=[df_pair.vB_max.std(), df_pair.vB_low.std(), df_pair.vB_high.std()], \n",
    "                 c=TASK_CLR[df_pair.iloc[0].task_2.task], marker='o', capsize=5)\n",
    "    for i in range(len(df_pair)):\n",
    "        row = df_pair.iloc[i]\n",
    "        plt.plot([0,1,2], [row.vA_max, row.vA_low, row.vA_high], c=TASK_CLR[row.task_1.task], alpha=0.3, lw=1)\n",
    "        plt.plot([0,1,2], [row.vB_max, row.vB_low, row.vB_high], c=TASK_CLR[row.task_2.task], alpha=0.3, lw=1)\n",
    "    \n",
    "    plt.xlim([-0.5,2.5])\n",
    "    plt.ylim([0,1])\n",
    "    plt.xticks([0,1,2], ['Top factors', 'More aligned', 'Less aligned'], rotation=45)\n",
    "    plt.yticks(np.linspace(0,1,6), np.linspace(0,100,6).astype(int))\n",
    "    plt.ylabel('Variance explained (%)')\n",
    "plt.subplots_adjust(left=0.1, right=0.9, bottom=0.2, top=0.9, wspace=0.5)\n",
    "\n",
    "save_plot_dir = os.path.join('plots', 'principal_angles')\n",
    "if not os.path.exists(save_plot_dir):\n",
    "    os.makedirs(save_plot_dir)\n",
    "if SAVEFIG:\n",
    "    for ext in ['png','svg']:\n",
    "        plt.savefig(os.path.join(save_plot_dir, f'subspace_alignment.' + ext))\n",
    "plt.show()\n",
    "\n",
    "df = pd.melt(df_pair, id_vars=['task_pair'], value_vars=['vA_max', 'vA_low', 'vA_high', 'vB_max', 'vB_low', 'vB_high'],\n",
    "             var_name='type', value_name='var_exp')\n",
    "\n",
    "df['session'] = df['type'].str.split('_').str[0]\n",
    "df['alignment'] = df['type'].str.split('_').str[1]\n",
    "\n",
    "pg.anova(dv='var_exp', between=['session', 'alignment'], data=df)\n",
    "pg.pairwise_tests(dv='var_exp', between=['session', 'alignment'], data=df, padjust='bonf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3334b258",
   "metadata": {
    "title": "Compare d_shared obtained by two different methods"
   },
   "outputs": [],
   "source": [
    "## Figure S1.\n",
    "thres_component = []\n",
    "cv_component = []\n",
    "\n",
    "all_results = {}\n",
    "for i in range(len(df_singles)):\n",
    "    # Check the d_shared obtained by two different methods\n",
    "    s = df_singles.iloc[i].session_class\n",
    "    fa_thres = fa.fa_fit(s.Y_norm, shared_var_thresh=0.95, max_iter=int(100))\n",
    "    fa_cv = fa.fa_fit(s.Y_norm, cv_components=np.arange(s.Y_norm.shape[1]), max_iter=int(100))\n",
    "    thres_component.append(fa_thres['d_shared'])\n",
    "    cv_component.append(fa_cv['d_shared'])\n",
    "    all_results[s.session_key] = {\n",
    "        'fa_thres': fa_thres,\n",
    "        'fa_cv': fa_cv\n",
    "    }\n",
    "\n",
    "\n",
    "model_dir = os.path.join('models')\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "joblib.dump(all_results, os.path.join(model_dir, 'fa_cv_vs_95.pkl'))\n",
    "\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.scatter(thres_component, cv_component, s=20, ec='k', fc='none')\n",
    "plt.plot([0,50],[0,50], c='k', ls='--')\n",
    "plt.xlabel('d_shared by shared_var_thresh=0.95')\n",
    "plt.ylabel('d_shared by CV')\n",
    "\n",
    "save_plot_dir = os.path.join('plots', 'general_plots')\n",
    "if not os.path.exists(save_plot_dir):\n",
    "    os.makedirs(save_plot_dir)\n",
    "if SAVEFIG:\n",
    "    for ext in ['png','svg']:\n",
    "        plt.savefig(os.path.join(save_plot_dir, f'd_shared_cv_vs_95.' + ext))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4d53ff",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "Regional difference - simple stats"
   },
   "outputs": [],
   "source": [
    "## Figure S2. Panel A and B.\n",
    "\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.hist(hpc, bins=np.linspace(-0.5,2,26), color=AREA_CLR['HPC'], alpha=0.5, edgecolor='k', density=True, label='HPC')\n",
    "plt.hist(acc, bins=np.linspace(-0.5,2,26), color=AREA_CLR['ACC'], alpha=0.5, edgecolor='k', density=True, label='ACC')\n",
    "plt.title(f'Two-sample Welch, t({dof:.2f})={stats:.3f}, p={pval:.2e}')\n",
    "plt.xlabel('Log firing rate (10^ Hz)')\n",
    "plt.ylabel('Density')\n",
    "plt.subplots_adjust(hspace=0.1,left=0.2,right=0.9,bottom=0.2)\n",
    "plt.legend(frameon=False)\n",
    "\n",
    "save_plot_dir = os.path.join('plots', 'regional_difference')\n",
    "if not os.path.exists(save_plot_dir):\n",
    "    os.makedirs(save_plot_dir)\n",
    "if SAVEFIG:\n",
    "    for ext in ['png','svg']:\n",
    "        plt.savefig(os.path.join(save_plot_dir, 'mean_firing_rate.' + ext))\n",
    "plt.show()\n",
    "\n",
    "hpc, acc = [], []\n",
    "for i in range(len(df_singles)):\n",
    "    s = df_singles.iloc[i].session_class\n",
    "    hpc.extend(s.FA.shared_var_per_unit[s.hpc_ix])\n",
    "    acc.extend(s.FA.shared_var_per_unit[s.acc_ix])\n",
    "\n",
    "\n",
    "res = pg.ttest(hpc,acc, paired=False)\n",
    "stats = res.iloc[0]['T']\n",
    "pval = res.iloc[0]['p-val']\n",
    "dof = res.iloc[0]['dof']\n",
    "\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.hist(hpc, bins=np.linspace(0,1,21), color=AREA_CLR['HPC'], alpha=0.5, edgecolor='k', density=True, label='HPC')\n",
    "plt.hist(acc, bins=np.linspace(0,1,21), color=AREA_CLR['ACC'], alpha=0.5, edgecolor='k', density=True, label='ACC')\n",
    "plt.title(f'Two-sample Welch, t({dof:.2f})={stats:.3f}, p={pval:.2e}')\n",
    "plt.xlabel('Shared variance per unit')\n",
    "plt.ylabel('Density')\n",
    "plt.subplots_adjust(hspace=0.1,left=0.2,right=0.9,bottom=0.2)\n",
    "plt.legend(frameon=False)\n",
    "\n",
    "save_plot_dir = os.path.join('plots', 'regional_difference')\n",
    "if not os.path.exists(save_plot_dir):\n",
    "    os.makedirs(save_plot_dir)\n",
    "if SAVEFIG:\n",
    "    for ext in ['png','svg']:\n",
    "        plt.savefig(os.path.join(save_plot_dir, 'shared_var_per_unit.' + ext))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe82dbb",
   "metadata": {
    "title": "Regional difference - shared var not correlated with firing"
   },
   "outputs": [],
   "source": [
    "## Figure S2. Panel C, D, and E.\n",
    "plt.figure(figsize=(9,3))\n",
    "for j in range(len(TASK_NAMES)):\n",
    "    dfs = get_single_task_df(df_singles, TASK_NAMES[j])\n",
    "    svpu, mfr, region = [], [], []\n",
    "    plt.subplot(1,3,j+1)\n",
    "    for i in range(len(dfs)):\n",
    "        s = dfs.iloc[i].session_class\n",
    "        svpu.extend(s.FA.shared_var_per_unit)\n",
    "        mfr.extend(s.spikes_mu)\n",
    "        region.extend(s.hpc_ix)\n",
    "    svpu = np.array(svpu)\n",
    "    mfr = np.array(mfr)\n",
    "    region = np.array(region)\n",
    "\n",
    "    dd = pd.DataFrame({\n",
    "        'shared_var_per_unit': svpu,\n",
    "        'firing_rate': mfr, \n",
    "        'HPC': region.astype(int),\n",
    "        'ACC': np.logical_not(region).astype(int)})\n",
    "    result = sm.ols(formula='shared_var_per_unit ~ firing_rate + HPC + ACC', data=dd).fit()\n",
    "\n",
    "    plt.scatter(mfr,svpu, s=5, ec=[AREA_CLR['HPC'] if i==True else AREA_CLR['ACC'] for i in region], fc='none')\n",
    "    plt.xscale('log')\n",
    "    plt.ylabel('Shared variance per unit')\n",
    "    plt.xlabel('Mean firing rate (Hz)')\n",
    "    hpc_corr = np.corrcoef(svpu[region], mfr[region])[0,1]\n",
    "    acc_corr = np.corrcoef(svpu[~region], mfr[~region])[0,1]\n",
    "    plt.title(f\"\"\"{TASK_NAMES[j]}\n",
    "Corr: HPC {hpc_corr:.2f}, ACC {acc_corr:.2f}\n",
    "p-val: firing rate {result.pvalues['firing_rate']:.2e}\n",
    "HPC {result.pvalues['HPC']:.2e}\n",
    "ACC {result.pvalues['ACC']:.2e}\n",
    "\"\"\", fontsize=10)\n",
    "plt.subplots_adjust(left=0.1, right=0.9, wspace=0.5, top=0.7, bottom=0.1)\n",
    "save_plot_dir = os.path.join('plots', 'regional_difference')\n",
    "if not os.path.exists(save_plot_dir):\n",
    "    os.makedirs(save_plot_dir)\n",
    "if SAVEFIG:\n",
    "    for ext in ['png','svg']:\n",
    "        plt.savefig(os.path.join(save_plot_dir, f'shared_var_per_unit_firing_rate.' + ext))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d0e7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Figure S3.\n",
    "plt.figure(figsize=(9,3))\n",
    "\n",
    "for j in range(len(TASK_NAMES)):\n",
    "    dfs = get_single_task_df(df_singles[(df_singles['Patient']!='YEY')&(df_singles['Patient']!='YEZ')],\n",
    "                             TASK_NAMES[j])\n",
    "    plt.subplot(1,3,j+1)\n",
    "    hpc_power, svpd = [], []\n",
    "    for i in range(len(dfs)):\n",
    "        s = dfs.iloc[i].session_class\n",
    "        [_,S,_] = np.linalg.svd(s.FA.first_d_components) # Have to use pre-orthonorm otherwise S would all be 1\n",
    "        svpd.extend(S**2 / np.sum(S**2))\n",
    "        total_var_per_unit_per_dim = (s.FA.subspace)**2 # (d, N)\n",
    "        hpc_power.extend(total_var_per_unit_per_dim[:, s.hpc_ix].sum(axis=1) * 100)\n",
    "    r, pval = scipy.stats.pearsonr(np.array(hpc_power), np.array(svpd))\n",
    "    \n",
    "    plt.scatter(hpc_power, svpd, fc='none', ec=AREA_CLR['HPC'], s=10, lw=0.5)\n",
    "    plt.ylabel('Shared variance per dim')\n",
    "    plt.xlabel('% shared variance')\n",
    "    plt.title(f'{TASK_NAMES[j]}\\nr={r:.3f}, p={pval:.2e}, n={len(svpd)}',fontsize=10)\n",
    "    plt.subplots_adjust(wspace=0.6, bottom=0.3)\n",
    "save_plot_dir = os.path.join('plots', 'regional_difference')\n",
    "if not os.path.exists(save_plot_dir):\n",
    "    os.makedirs(save_plot_dir)\n",
    "if SAVEFIG:\n",
    "    for ext in ['png','svg']:\n",
    "        plt.savefig(os.path.join(save_plot_dir, f'hpc_sv_and_svpd.' + ext))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8405e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Figure S4. \n",
    "dfs = df_singles[(df_singles.Patient!='YEY')&(df_singles.Patient!='YEZ')]\n",
    "hpc_diffs, acc_diffs = [], []\n",
    "for j in range(len(TASK_NAMES)):\n",
    "    df = get_single_task_df(dfs, TASK_NAMES[j])\n",
    "\n",
    "    hpc_svpu, acc_svpu, hpc_svpu_add, acc_svpu_add = [], [] ,[] ,[]\n",
    "    hpc_diff, acc_diff = [], []\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        print(f'{i} out of {len(df)} sessions in {TASK_NAMES[j]}')\n",
    "        s = df.iloc[i].session_class\n",
    "        Y = s.Y_norm\n",
    "\n",
    "        # Fit FA for each region and both regions\n",
    "        FA_hpc = io.FactorAnalysisResult(fa.fa_fit(Y[:, s.hpc_ix]))\n",
    "        FA_acc = io.FactorAnalysisResult(fa.fa_fit(Y[:, s.acc_ix]))\n",
    "        FA_all = io.FactorAnalysisResult(fa.fa_fit(Y))\n",
    "\n",
    "        # Store shared var per unit\n",
    "        hpc_svpu.extend(FA_hpc.shared_var_per_unit) # HPC's sv per unit (svpu) when fitting HPC only\n",
    "        acc_svpu.extend(FA_acc.shared_var_per_unit) # ACC's svpu when fitting ACC only\n",
    "        hpc_svpu_add.extend(FA_all.shared_var_per_unit[s.hpc_ix]) # HPC's svpu when fitting both regions\n",
    "        acc_svpu_add.extend(FA_all.shared_var_per_unit[s.acc_ix]) # ACC's svpu when fitting both regions\n",
    "\n",
    "        # Also store the difference\n",
    "        hpc_diff.extend(FA_all.shared_var_per_unit[s.hpc_ix] - FA_hpc.shared_var_per_unit)\n",
    "        acc_diff.extend(FA_all.shared_var_per_unit[s.acc_ix] - FA_acc.shared_var_per_unit)\n",
    "\n",
    "    hpc_diffs.extend(hpc_diff)\n",
    "    acc_diffs.extend(acc_diff)\n",
    "    \n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.scatter(hpc_svpu, hpc_svpu_add, s=10, ec=AREA_CLR['HPC'], fc='none')\n",
    "    plt.scatter(acc_svpu, acc_svpu_add, s=10, ec=AREA_CLR['ACC'], fc='none')\n",
    "    plt.xlabel('sv per unit, fitting single region')\n",
    "    plt.ylabel('sv per unit, fitting both regions')\n",
    "    plt.plot([1e-4,1],[1e-4,1], c='k', ls='--', alpha=0.4)\n",
    "    plt.title(f'{TASK_NAMES[j]}, thres=CV')\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    plt.subplots_adjust(left=0.2, right=0.8, top=0.8, bottom=0.2)\n",
    "\n",
    "    save_plot_dir = os.path.join('plots', 'regional_difference', 'one_vs_both_regions')\n",
    "    if not os.path.exists(save_plot_dir):\n",
    "        os.makedirs(save_plot_dir)\n",
    "    if SAVEFIG:\n",
    "        for ext in ['png','svg']:\n",
    "            plt.savefig(os.path.join(save_plot_dir, f'{TASK_NAMES[j]}_95.' + ext))\n",
    "    plt.show()\n",
    "\n",
    "    stats, pval = scipy.stats.ttest_1samp(acc_diff, 0, alternative='greater')\n",
    "    acc_info = f'ACC: t({len(acc_diff)-1})={stats:.3f}, p={pval:.2e}'\n",
    "    stats, pval = scipy.stats.ttest_1samp(hpc_diff, 0, alternative='greater')\n",
    "    hpc_info = f'HPC: t({len(hpc_diff)-1})={stats:.3f}, p={pval:.2e}'\n",
    "    stats, pval = scipy.stats.ttest_ind(acc_diff, hpc_diff, alternative='greater')\n",
    "    diff_info = f'∆: t({len(hpc_diff)+len(acc_diff)-2})={stats:.3f}, p={pval:.2e}'\n",
    "    fig, ax = plt.subplots(1,1,figsize=(4,4))\n",
    "    sns.kdeplot(hpc_diff, ax=ax,color=AREA_CLR['HPC'])\n",
    "    sns.kdeplot(acc_diff, ax=ax,color=AREA_CLR['ACC'])\n",
    "    ax.set_xlim([-0.3,0.3])\n",
    "\n",
    "    ax.set_title(f'{hpc_info}\\n{acc_info}\\n{diff_info}', fontsize=10)\n",
    "    ax.set_xlabel('∆ shared var')\n",
    "    ax.set_ylabel('Density')\n",
    "    plt.subplots_adjust(left=0.2, right=0.8, top=0.7, bottom=0.2)\n",
    "\n",
    "    save_plot_dir = os.path.join('plots', 'regional_difference', 'one_vs_both_regions')\n",
    "    if not os.path.exists(save_plot_dir):\n",
    "        os.makedirs(save_plot_dir)\n",
    "    if SAVEFIG:\n",
    "        for ext in ['png','svg']:\n",
    "            plt.savefig(os.path.join(save_plot_dir, f'{TASK_NAMES[j]}_diff_95.' + ext))\n",
    "    plt.show()\n",
    "\n",
    "stats, pval = scipy.stats.ttest_1samp(acc_diffs, 0, alternative='greater')\n",
    "acc_info = f'ACC: t({len(acc_diffs)-1})={stats:.3f}, p={pval:.2e}'\n",
    "stats, pval = scipy.stats.ttest_1samp(hpc_diffs, 0, alternative='greater')\n",
    "hpc_info = f'HPC: t({len(hpc_diffs)-1})={stats:.3f}, p={pval:.2e}'\n",
    "stats, pval = scipy.stats.ttest_ind(acc_diffs, hpc_diffs, alternative='greater')\n",
    "diff_info = f'∆: t({len(hpc_diffs)+len(acc_diffs)-2})={stats:.3f}, p={pval:.2e}'\n",
    "fig, ax = plt.subplots(1,1,figsize=(4,4))\n",
    "sns.kdeplot(hpc_diffs, ax=ax,color=AREA_CLR['HPC'])\n",
    "sns.kdeplot(acc_diffs, ax=ax,color=AREA_CLR['ACC'])\n",
    "\n",
    "ax.set_xlim([-0.4,0.4])\n",
    "ax.set_title(f'{hpc_info}\\n{acc_info}\\n{diff_info}', fontsize=10)\n",
    "ax.set_xlabel('∆ shared var')\n",
    "ax.set_ylabel('Density')\n",
    "plt.subplots_adjust(left=0.2, right=0.8, top=0.7, bottom=0.2)\n",
    "\n",
    "save_plot_dir = os.path.join('plots', 'regional_difference', 'one_vs_both_regions')\n",
    "if not os.path.exists(save_plot_dir):\n",
    "    os.makedirs(save_plot_dir)\n",
    "if SAVEFIG:\n",
    "    for ext in ['png','svg']:\n",
    "        plt.savefig(os.path.join(save_plot_dir, f'diff_95_ALL.' + ext))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966ad4d7",
   "metadata": {
    "title": "Plot geodesic distance"
   },
   "outputs": [],
   "source": [
    "## Figure S6.\n",
    "df_pairs = get_paired_df(df_singles)\n",
    "df_pairs_both = add_distance_metrics(df_pairs, mode=\"both\", niters_rand=100, niters_shuf=30)\n",
    "\n",
    "df_pairs = df_pairs[(df_pairs.subj!='Y') & (df_pairs.subj!='Z')]\n",
    "if not hasattr(df_pairs.iloc[0].task_1, \"FA_acc\"):\n",
    "    for _, row in df_pairs.iterrows():\n",
    "        s1, s2 = row.task_1, row.task_2\n",
    "        s1.FA_acc = s1.find_subspace(s1.Y[:, s1.acc_ix], verbose=False)\n",
    "        s1.FA_hpc = s1.find_subspace(s1.Y[:, s1.hpc_ix], verbose=False)\n",
    "        s2.FA_acc = s2.find_subspace(s2.Y[:, s2.acc_ix], verbose=False)\n",
    "        s2.FA_hpc = s2.find_subspace(s2.Y[:, s2.hpc_ix], verbose=False)\n",
    "\n",
    "df_pairs_hpc = add_distance_metrics(df_pairs, mode=\"hpc\", niters_rand=100, niters_shuf=30)\n",
    "df_pairs_acc = add_distance_metrics(df_pairs, mode=\"acc\", niters_rand=30, niters_shuf=30)\n",
    "\n",
    "plot_geodesic_distance(df_pairs_both, \"both\", savefig=SAVEFIG)\n",
    "plot_geodesic_distance(df_pairs_hpc, \"hpc\", savefig=SAVEFIG)\n",
    "plot_geodesic_distance(df_pairs_acc, \"acc\", savefig=SAVEFIG)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "title,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "subspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
